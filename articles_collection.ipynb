{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1b054e",
   "metadata": {},
   "source": [
    "# Articles Collection\n",
    "\n",
    "This notebook performs web scraping and downloads all [archived articles](https://thescipub.com/jcs/archive) in Journal of Computer Science provided by [Science Publications](https://thescipub.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c418a",
   "metadata": {},
   "source": [
    "## Web-Scraping: Retrieve Issue Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b40810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url of Science Publications web page\n",
    "main_url = 'https://thescipub.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94bc3ef",
   "metadata": {},
   "source": [
    "### Retrieve Issue Urls for all Journal Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86f10b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue#</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>https://thescipub.com/jcs/issue/1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>https://thescipub.com/jcs/issue/1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>https://thescipub.com/jcs/issue/1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>https://thescipub.com/jcs/issue/1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>https://thescipub.com/jcs/issue/1303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Volume  Issue#                                  urls\n",
       "0  2021      17       1  https://thescipub.com/jcs/issue/1273\n",
       "1  2021      17       2  https://thescipub.com/jcs/issue/1288\n",
       "2  2021      17       3  https://thescipub.com/jcs/issue/1292\n",
       "3  2021      17       4  https://thescipub.com/jcs/issue/1299\n",
       "4  2021      17       5  https://thescipub.com/jcs/issue/1303"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = []       # year of publication\n",
    "volumes = []     # volume number\n",
    "issues = []      # issue number in a given Volume\n",
    "urls = []        # url of Journal's issue\n",
    "\n",
    "# grab contents from the archive page for Journal of Computer Science\n",
    "page = requests.get(main_url + '/jcs/archive')\n",
    "\n",
    "# create BeautifulSoup object\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# get all divs with class 'pkp_block'\n",
    "components = soup.find_all('div', class_='pkp_block')\n",
    "\n",
    "# iterate through every div with class 'pkp_block'\n",
    "for c in components:\n",
    "    # get the text for h2 tag: yyyy - VolumeNumber\n",
    "    volume_text = c.find('h2').get_text().split(\" \")\n",
    "    \n",
    "    # get all Issue urls for a given Volume\n",
    "    links = c.find_all('a', href=True)\n",
    "    \n",
    "    # iterate through the urls\n",
    "    # and append data to the lists (years, volumes, issues, urls) for data frame creation\n",
    "    for a in links:\n",
    "        years.append(int(volume_text[0]))\n",
    "        volumes.append(int(volume_text[-1]))\n",
    "        issues.append(int(a.get_text().split(' ')[-1]))\n",
    "        urls.append(main_url + a['href'])\n",
    "\n",
    "# create a Pandas data frame\n",
    "journal_archive = pd.DataFrame(dict({'Year': years, 'Volume': volumes, 'Issue#': issues, 'urls': urls}))\n",
    "\n",
    "# display the first 5 rows of data frame\n",
    "journal_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07410f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "journal_archive.to_csv('data/journal_archive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9564300",
   "metadata": {},
   "source": [
    "## Web-Scraping: Download Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44b6ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.16it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.09it/s]\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.03it/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.41it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.30it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.68it/s]\n",
      "100%|██████████| 16/16 [00:06<00:00,  2.43it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.34it/s]\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
      "100%|██████████| 17/17 [00:07<00:00,  2.15it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.20it/s]\n",
      "100%|██████████| 14/14 [00:06<00:00,  2.25it/s]\n",
      "100%|██████████| 14/14 [00:08<00:00,  1.69it/s]\n",
      "100%|██████████| 12/12 [00:06<00:00,  1.74it/s]\n",
      "100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.11it/s]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.58it/s]\n",
      "100%|██████████| 14/14 [00:06<00:00,  2.17it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.44it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.27it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.74it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.07it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.01it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.13it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.30it/s]\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.50it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.75it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.72it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.71it/s]\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.24it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.73it/s]\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.77it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.19it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.87it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.40it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.76it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.62it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.82it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.50it/s]\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.59it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.84it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.68it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.07it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.71it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.44it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.56it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.97it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.62it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.81it/s]\n",
      "100%|██████████| 21/21 [00:07<00:00,  2.95it/s]\n",
      "100%|██████████| 16/16 [00:05<00:00,  2.91it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.72it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.69it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.84it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.09it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.68it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.00it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.71it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.67it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.02it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.02it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.62it/s]\n",
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.98it/s]\n",
      "100%|██████████| 30/30 [00:10<00:00,  3.00it/s]\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.07it/s]\n",
      "100%|██████████| 18/18 [00:06<00:00,  2.89it/s]\n",
      "100%|██████████| 34/34 [00:11<00:00,  2.97it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.96it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.91it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.69it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.79it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.99it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.85it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.78it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.13it/s]\n",
      "100%|██████████| 21/21 [00:06<00:00,  3.16it/s]\n",
      "100%|██████████| 22/22 [00:07<00:00,  2.88it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.97it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.21it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.89it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.93it/s]\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.07it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.99it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.77it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.87it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  2.87it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.69it/s]\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.55it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.07it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.83it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.16it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.15it/s]\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.17it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.10it/s]\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.11it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.37it/s]\n",
      "100%|██████████| 22/22 [00:07<00:00,  3.00it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.00it/s]\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n",
      "100%|██████████| 18/18 [00:06<00:00,  2.87it/s]\n",
      "100%|██████████| 21/21 [00:06<00:00,  3.21it/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  3.14it/s]\n",
      "100%|██████████| 19/19 [00:06<00:00,  2.99it/s]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.76it/s]\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.08it/s]\n",
      "100%|██████████| 16/16 [00:05<00:00,  2.68it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.85it/s]\n",
      "100%|██████████| 31/31 [00:10<00:00,  3.07it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  2.92it/s]\n",
      "100%|██████████| 24/24 [00:08<00:00,  2.99it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.77it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.02it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  3.00it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.79it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.34it/s]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.18it/s]\n",
      "100%|██████████| 27/27 [00:08<00:00,  3.10it/s]\n",
      "100%|██████████| 11/11 [00:03<00:00,  2.85it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  2.83it/s]\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.82it/s]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n",
      "100%|██████████| 11/11 [00:03<00:00,  3.05it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.62it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.03it/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  3.06it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n",
      "100%|██████████| 11/11 [00:03<00:00,  2.76it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.08it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.87it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.92it/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  3.22it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.00it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  3.09it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.87it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.01it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\n",
      "100%|██████████| 19/19 [00:05<00:00,  3.20it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.24it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.10it/s]\n",
      "100%|██████████| 13/13 [00:04<00:00,  3.20it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.26it/s]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.74it/s]\n",
      "100%|██████████| 8/8 [00:02<00:00,  2.86it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.89it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.37it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.02it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.51it/s]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.67it/s]\n",
      "100%|██████████| 24/24 [00:12<00:00,  1.89it/s]\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.16it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "titles = []             # article titles\n",
    "article_urls = []       # article's url to download pdf file\n",
    "file_names = []         # name of article's pdf file saved in local machine\n",
    "\n",
    "# iterate through every Journal Issue's url\n",
    "for i, issue_url in enumerate(urls):\n",
    "    # grab contents from a webpage\n",
    "    page = requests.get(issue_url)\n",
    "    \n",
    "    # create BeautifulSoup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # get all divs with class 'obj_article_summary'\n",
    "    components = soup.find_all('div', class_='obj_article_summary')\n",
    "    \n",
    "    # iterate through every div with class 'obj_article_summary'\n",
    "    # and append data to the lists (titles, article_urls, file_names) for data frame creation\n",
    "    for c in tqdm(components):\n",
    "        # get article's title\n",
    "        titles.append(c.find('div', class_='title').get_text())\n",
    "        \n",
    "        # get url of pdf file\n",
    "        link = c.find('div', class_='galley_link').find('a', href=True)\n",
    "        url = main_url + link['href']\n",
    "        \n",
    "        # name of article's pdf saved in local machine\n",
    "        filename = str(years[i]) + '_' + str(volumes[i]) + '_' + str(issues[i]) + '_' + url.split('/')[-1]\n",
    "        file_names.append(filename)\n",
    "        article_urls.append(url)\n",
    "        \n",
    "        # download article and save to local machine under folder 'articles'\n",
    "        response = requests.get(url)\n",
    "        with open('articles/' + filename, 'wb') as pdf:\n",
    "            pdf.write(response.content)\n",
    "        \n",
    "        response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76186833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>File Name</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Systematic Literature Review on English and ...</td>\n",
       "      <td>2021_17_1_jcssp.2021.1.18.pdf</td>\n",
       "      <td>https://thescipub.com/pdf/jcssp.2021.1.18.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAD: A Detailed Arabic Dataset for Online Text...</td>\n",
       "      <td>2021_17_1_jcssp.2021.19.32.pdf</td>\n",
       "      <td>https://thescipub.com/pdf/jcssp.2021.19.32.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Collision Avoidance Modelling in Airline Traff...</td>\n",
       "      <td>2021_17_1_jcssp.2021.33.43.pdf</td>\n",
       "      <td>https://thescipub.com/pdf/jcssp.2021.33.43.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fine-Tuned MobileNet Classifier for Classifica...</td>\n",
       "      <td>2021_17_1_jcssp.2021.44.54.pdf</td>\n",
       "      <td>https://thescipub.com/pdf/jcssp.2021.44.54.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Content Filtering from Spam Posts on Social ...</td>\n",
       "      <td>2021_17_1_jcssp.2021.55.66.pdf</td>\n",
       "      <td>https://thescipub.com/pdf/jcssp.2021.55.66.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Systematic Literature Review on English and ...   \n",
       "1  DAD: A Detailed Arabic Dataset for Online Text...   \n",
       "2  Collision Avoidance Modelling in Airline Traff...   \n",
       "3  Fine-Tuned MobileNet Classifier for Classifica...   \n",
       "4  A Content Filtering from Spam Posts on Social ...   \n",
       "\n",
       "                        File Name  \\\n",
       "0   2021_17_1_jcssp.2021.1.18.pdf   \n",
       "1  2021_17_1_jcssp.2021.19.32.pdf   \n",
       "2  2021_17_1_jcssp.2021.33.43.pdf   \n",
       "3  2021_17_1_jcssp.2021.44.54.pdf   \n",
       "4  2021_17_1_jcssp.2021.55.66.pdf   \n",
       "\n",
       "                                              URL  \n",
       "0   https://thescipub.com/pdf/jcssp.2021.1.18.pdf  \n",
       "1  https://thescipub.com/pdf/jcssp.2021.19.32.pdf  \n",
       "2  https://thescipub.com/pdf/jcssp.2021.33.43.pdf  \n",
       "3  https://thescipub.com/pdf/jcssp.2021.44.54.pdf  \n",
       "4  https://thescipub.com/pdf/jcssp.2021.55.66.pdf  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a data frame for articles\n",
    "articles = pd.DataFrame(dict({'Title': titles, 'File Name': file_names, 'URL': article_urls}))\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a383a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save articles as csv file\n",
    "articles.to_csv('data/articles.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
